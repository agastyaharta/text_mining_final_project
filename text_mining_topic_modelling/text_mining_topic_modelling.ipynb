{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d5aaa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18eb6c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 .txt files\n",
      " - Crime_and_Punishment.txt\n",
      " - Notes_from_the_Underground.txt\n",
      " - Poor_Folk.txt\n",
      " - Short_Stories.txt\n",
      " - The_Brothers_Karamazov.txt\n",
      " - The_Gambler.txt\n",
      " - The_Grand_Inquisitor.txt\n",
      " - The_Idiot.txt\n",
      " - The_Possessed _or_The_Devils.txt\n",
      " - White_Nights_and_Other_Stories.txt\n",
      "Loaded books: ['Crime_and_Punishment', 'Notes_from_the_Underground', 'Poor_Folk', 'Short_Stories', 'The_Brothers_Karamazov']\n"
     ]
    }
   ],
   "source": [
    "RAW_DIR = Path(\"data_raw\")\n",
    "raw_files = sorted(RAW_DIR.glob(\"*.txt\"))\n",
    "\n",
    "print(f\"Found {len(raw_files)} .txt files\")\n",
    "for f in raw_files[:10]:\n",
    "    print(\" -\", f.name)\n",
    "\n",
    "def read_text(fp: Path) -> str:\n",
    "    try:\n",
    "        return fp.read_text(encoding=\"utf-8\")\n",
    "    except UnicodeDecodeError:\n",
    "        return fp.read_text(encoding=\"latin-1\")\n",
    "\n",
    "raw_texts = {fp.stem: read_text(fp) for fp in raw_files}\n",
    "print(\"Loaded books:\", list(raw_texts.keys())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a79df9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example book: Crime_and_Punishment\n",
      "CRIME AND PUNISHMENT\n",
      "\n",
      "\n",
      "\n",
      "PART I\n",
      "\n",
      "\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "On an exceptionally hot evening early in July a young man came out of\n",
      "the garret in which he lodged in S. Place and walked slowly, as though\n",
      "in hesitation, towards K. bridge.\n",
      "\n",
      "He had successfully avoided meeting his landlady on the staircase. His\n",
      "garret was under the roof of a high, five-storied house and was more\n",
      "like a cupboard than a room. The landlady who provided him with garret,\n",
      "dinners, and attendance, lived on the floor below, and every time\n",
      "h\n"
     ]
    }
   ],
   "source": [
    "texts = {fp.stem: read_text(fp) for fp in raw_files}\n",
    "\n",
    "first_key = next(iter(texts))\n",
    "print(\"Example book:\", first_key)\n",
    "print(texts[first_key][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c739305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIME AND PUNISHMENT\n",
      "\n",
      "\n",
      "\n",
      "PART I\n",
      "\n",
      "\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "On an exceptionally hot evening early in July a young man came out of\n",
      "the garret in which he lodged in S. Place and walked slowly as though\n",
      "in hesitation towards K. bridge.\n",
      "\n",
      "He had successfully avoided meeting his landlady on the staircase. His\n",
      "garret was under the roof of a high fivestoried house and was more\n",
      "like a cupboard than a room. The landlady who provided him with garret\n",
      "dinners and attendance lived on the floor below and every time\n",
      "he went o\n"
     ]
    }
   ],
   "source": [
    "def prelim_clean(text: str) -> str:\n",
    "    return re.sub(r\"[^a-zA-Z0-9 \\n\\.\\']\", '', text)\n",
    "\n",
    "prelim_texts = {}\n",
    "for book, text in texts.items():\n",
    "    prelim = prelim_clean(text)\n",
    "    prelim_texts[book] = prelim\n",
    "\n",
    "print(prelim_texts[first_key][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbfcbf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIME AND PUNISHMENT\n",
      "\n",
      "\n",
      "\n",
      "PART I\n",
      "\n",
      "\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "On an exceptionally hot evening early in July a young man came out of\n",
      "the garret in which he lodged in S Place and walked slowly as though\n",
      "in hesitation towards K bridge\n",
      "\n",
      "He had successfully avoided meeting his landlady on the staircase His\n",
      "garret was under the roof of a high fivestoried house and was more\n",
      "like a cupboard than a room The landlady who provided him with garret\n",
      "dinners and attendance lived on the floor below and every time\n",
      "he went out he\n"
     ]
    }
   ],
   "source": [
    "def remove_extra_spaces(text: str) -> str:\n",
    "    return re.sub(r' +', ' ', text)\n",
    "\n",
    "def remove_punctuation_remaining(text: str) -> str:\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "def remove_numbers(text: str) -> str:\n",
    "    return re.sub(r'\\d', '', text)\n",
    "\n",
    "clean_texts = {}\n",
    "for book, text in prelim_texts.items():\n",
    "    t = remove_extra_spaces(text)\n",
    "    t = remove_punctuation_remaining(t)\n",
    "    t = remove_numbers(t)\n",
    "    clean_texts[book] = t\n",
    "\n",
    "print(clean_texts[first_key][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1c7364a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crime and punishment\n",
      "\n",
      "\n",
      "\n",
      "part i\n",
      "\n",
      "\n",
      "\n",
      "chapter i\n",
      "\n",
      "on an exceptionally hot evening early in july a young man came out of\n",
      "the garret in which he lodged in s place and walked slowly as though\n",
      "in hesitation towards k bridge\n",
      "\n",
      "he had successfully avoided meeting his landlady on the staircase his\n",
      "garret was under the roof of a high fivestoried house and was more\n",
      "like a cupboard than a room the landlady who provided him with garret\n",
      "dinners and attendance lived on the floor below and every time\n",
      "he went out he\n"
     ]
    }
   ],
   "source": [
    "lower_texts = {book: text.lower() for book, text in clean_texts.items()}\n",
    "print(lower_texts[first_key][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1315adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original token sample: ['crime', 'and', 'punishment', 'part', 'i', 'chapter', 'i', 'on', 'an', 'exceptionally', 'hot', 'evening', 'early', 'in', 'july', 'a', 'young', 'man', 'came', 'out', 'of', 'the', 'garret', 'in', 'which', 'he', 'lodged', 'in', 's', 'place', 'and', 'walked', 'slowly', 'as', 'though', 'in', 'hesitation', 'towards', 'k', 'bridge']\n",
      "After stopword removal: ['crime', 'punishment', 'part', 'chapter', 'exceptionally', 'hot', 'evening', 'early', 'july', 'young', 'man', 'came', 'garret', 'lodged', 'place', 'walked', 'slowly', 'though', 'hesitation', 'towards', 'k', 'bridge', 'successfully', 'avoided', 'meeting', 'landlady', 'staircase', 'garret', 'roof', 'high', 'fivestoried', 'house', 'like', 'cupboard', 'room', 'landlady', 'provided', 'garret', 'dinners', 'attendance']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stopwords(text: str) -> list[str]:\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    tokens = word_tokenize(text)\n",
    "    return [w for w in tokens if w not in stop_words and w.strip() != \"\"]\n",
    "\n",
    "filtered_tokens = {}\n",
    "filtered_texts = {}\n",
    "\n",
    "for book, text in lower_texts.items():\n",
    "    tokens_kept = remove_stopwords(text)\n",
    "    filtered_tokens[book] = tokens_kept\n",
    "    filtered_texts[book] = \" \".join(tokens_kept)\n",
    "\n",
    "print(\"Original token sample:\", word_tokenize(lower_texts[first_key])[:40])\n",
    "print(\"After stopword removal:\", filtered_tokens[first_key][:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7887bea8",
   "metadata": {},
   "source": [
    "maybe i'll do word count here and see what is the most recent word and see if i should remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cda5b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('one', 5555),\n",
       " ('would', 4298),\n",
       " ('said', 4082),\n",
       " ('know', 3602),\n",
       " ('though', 3273),\n",
       " ('man', 3123),\n",
       " ('could', 2975),\n",
       " ('come', 2809),\n",
       " ('dont', 2796),\n",
       " ('like', 2793),\n",
       " ('time', 2733),\n",
       " ('even', 2603),\n",
       " ('see', 2423),\n",
       " ('go', 2326),\n",
       " ('well', 2304),\n",
       " ('say', 2217),\n",
       " ('must', 2099),\n",
       " ('nothing', 1951),\n",
       " ('suddenly', 1914),\n",
       " ('little', 1905),\n",
       " ('last', 1874),\n",
       " ('prince', 1835),\n",
       " ('something', 1759),\n",
       " ('tell', 1734),\n",
       " ('never', 1687),\n",
       " ('away', 1678),\n",
       " ('old', 1671),\n",
       " ('thought', 1669),\n",
       " ('went', 1657),\n",
       " ('shall', 1590)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens = []\n",
    "for tokens in filtered_tokens.values():\n",
    "    all_tokens.extend(tokens)\n",
    "\n",
    "freq = Counter(all_tokens)\n",
    "freq.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebf53038",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "stemmed_tokens = {}\n",
    "stemmed_texts = {}\n",
    "\n",
    "for book, tokens in filtered_tokens.items(): \n",
    "    stems = [ps.stem(w) for w in tokens]\n",
    "    stemmed_tokens[book] = stems\n",
    "    stemmed_texts[book] = \" \".join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb814820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned books to: data_cleaned\n"
     ]
    }
   ],
   "source": [
    "BOOK_OUT = Path(\"data_cleaned\")\n",
    "BOOK_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for book, text in stemmed_texts.items():\n",
    "    (BOOK_OUT / f\"{book}_clean.txt\").write_text(text, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved cleaned books to:\", BOOK_OUT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
